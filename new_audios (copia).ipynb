{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Settings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import librosa\n",
    "#import numpy as np\n",
    "#import pandas as pd\n",
    "#import matplotlib.pyplot as plt\n",
    "#import librosa.display\n",
    "#import keras\n",
    "#import datetime\n",
    "#import seaborn as sns\n",
    "#from sklearn.preprocessing import LabelEncoder \n",
    "#from sklearn.model_selection import train_test_split\n",
    "#from sklearn.metrics import confusion_matrix\n",
    "#from sklearn.metrics import classification_report\n",
    "\n",
    "#plt.style.use('ggplot')\n",
    "#plt.rcParams['font.family'] = 'sans-serif' \n",
    "#plt.rcParams['font.serif'] = 'Ubuntu' \n",
    "#plt.rcParams['font.monospace'] = 'Ubuntu Mono' \n",
    "#plt.rcParams['font.size'] = 14 \n",
    "#plt.rcParams['axes.labelsize'] = 12 \n",
    "#plt.rcParams['axes.labelweight'] = 'bold' \n",
    "#plt.rcParams['axes.titlesize'] = 12 \n",
    "#plt.rcParams['xtick.labelsize'] = 12 \n",
    "#plt.rcParams['ytick.labelsize'] = 12 \n",
    "#plt.rcParams['legend.fontsize'] = 12 \n",
    "#plt.rcParams['figure.titlesize'] = 12 \n",
    "#plt.rcParams['image.cmap'] = 'jet' \n",
    "#plt.rcParams['image.interpolation'] = 'none' \n",
    "#plt.rcParams['figure.figsize'] = (10, 10) \n",
    "#plt.rcParams['axes.grid']=False\n",
    "#plt.rcParams['lines.linewidth'] = 2 \n",
    "#plt.rcParams['lines.markersize'] = 8\n",
    "#colors = ['xkcd:pale orange', 'xkcd:sea blue', 'xkcd:pale red', 'xkcd:sage green', 'xkcd:terra cotta', 'xkcd:dull purple', 'xkcd:teal', 'xkcd: goldenrod', 'xkcd:cadet blue',\n",
    "#'xkcd:scarlet']\n",
    "#bbox_props = dict(boxstyle=\"round,pad=0.3\", fc=colors[0], alpha=.5)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#requisits and ignore warnings\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "import fnmatch\n",
    "import collections\n",
    "import keras\n",
    "import librosa\n",
    "import csv\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras import models, layers\n",
    "from keras import backend as K\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from matplotlib import pyplot, cm\n",
    "from tqdm import tqdm\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y,sr = librosa.load('audios/Speaker26_000.wav')\n",
    "# dur_time = librosa.get_duration(y=y,sr=sr)\n",
    "#print(dur_time)\n",
    "#time_sec = round(dur_time)\n",
    "#S = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=20, fmax=8000)\n",
    "#fig, ax = plt.subplots()\n",
    "#S_dB = librosa.power_to_db(S, ref=np.max)\n",
    "#img = librosa.display.specshow(S_dB, x_axis='time',y_axis='mel', sr=sr,fmax=8000, ax=ax)\n",
    "#fig.colorbar(img, ax=ax, format='%+2.0f dB')\n",
    "#ax.set(title='Mel-frequency spectrogram')\n",
    "#plt.xlim()\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#time_series_sec=np.linspace(0, time_sec, len(S_dB[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of this section is the CSV files with the data to be handle by the model\n",
    "\n",
    "```\n",
    "trainData     : audio/train \n",
    "testData      : audio/test\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defines the names of the CSV files\n",
    "TRAIN_CSV_FILE = \"train.csv\"\n",
    "TEST_CSV_FILE = \"test.csv\"\n",
    "final_test=\"final_test.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib import cm\n",
    "import librosa\n",
    "import csv\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "def extractWavFeatures(soundFilesFolder, csvFileName):\n",
    "    print(\"The features of the files in the folder \"+soundFilesFolder+\" will be saved to \"+csvFileName)\n",
    "    header = 'filename chroma_stft rmse spectral_centroid spectral_bandwidth rolloff zero_crossing_rate'\n",
    "    for i in range(1, 21):\n",
    "        header += f' mfcc{i}'\n",
    "    header += ' label'\n",
    "    header = header.split()\n",
    "    print('CSV Header: ', header)\n",
    "    file = open(csvFileName, 'w', newline='')\n",
    "    #with file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(header)\n",
    "    count=0\n",
    "    for filename in tqdm(os.listdir(soundFilesFolder)):\n",
    "        number = f'{soundFilesFolder}/{filename}'\n",
    "        y, sr = librosa.load(number, mono=True, duration=30)\n",
    "        # remove leading and trailing silence\n",
    "        y, index = librosa.effects.trim(y)\n",
    "        chroma_stft = librosa.feature.chroma_stft(y=y, sr=sr)\n",
    "        rmse = librosa.feature.rms(y=y)\n",
    "        spec_cent = librosa.feature.spectral_centroid(y=y, sr=sr)\n",
    "        spec_bw = librosa.feature.spectral_bandwidth(y=y, sr=sr)\n",
    "        rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr)\n",
    "        zcr = librosa.feature.zero_crossing_rate(y)\n",
    "        mfcc = librosa.feature.mfcc(y=y, sr=sr)\n",
    "        to_append = f'{filename} {np.mean(chroma_stft)} {np.mean(rmse)} {np.mean(spec_cent)} {np.mean(spec_bw)} {np.mean(rolloff)} {np.mean(zcr)}'\n",
    "        for e in mfcc:\n",
    "            to_append += f' {np.mean(e)}'\n",
    "        writer.writerow(to_append.split())\n",
    "    file.close()\n",
    "    print(\"End of extractWavFeatures\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The features of the files in the folder audios/audios/train will be saved to train.csv\n",
      "CSV Header:  ['filename', 'chroma_stft', 'rmse', 'spectral_centroid', 'spectral_bandwidth', 'rolloff', 'zero_crossing_rate', 'mfcc1', 'mfcc2', 'mfcc3', 'mfcc4', 'mfcc5', 'mfcc6', 'mfcc7', 'mfcc8', 'mfcc9', 'mfcc10', 'mfcc11', 'mfcc12', 'mfcc13', 'mfcc14', 'mfcc15', 'mfcc16', 'mfcc17', 'mfcc18', 'mfcc19', 'mfcc20', 'label']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 14148/14148 [27:50<00:00,  8.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of extractWavFeatures\n",
      "CSV files are created\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#extractWavFeatures(\"new_audios/train\", TRAIN_CSV_FILE)\n",
    "#extractWavFeatures(\"new_audios/test\", TEST_CSV_FILE)\n",
    "extractWavFeatures(\"audios/audios/train\", TRAIN_CSV_FILE)\n",
    "print(\"CSV files are created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The features of the files in the folder audios/audios/test will be saved to test.csv\n",
      "CSV Header:  ['filename', 'chroma_stft', 'rmse', 'spectral_centroid', 'spectral_bandwidth', 'rolloff', 'zero_crossing_rate', 'mfcc1', 'mfcc2', 'mfcc3', 'mfcc4', 'mfcc5', 'mfcc6', 'mfcc7', 'mfcc8', 'mfcc9', 'mfcc10', 'mfcc11', 'mfcc12', 'mfcc13', 'mfcc14', 'mfcc15', 'mfcc16', 'mfcc17', 'mfcc18', 'mfcc19', 'mfcc20', 'label']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3586/3586 [04:33<00:00, 13.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of extractWavFeatures\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "extractWavFeatures(\"audios/audios/test\", TEST_CSV_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "from sklearn import preprocessing\n",
    "\n",
    "def preProcessData(csvFileName):\n",
    "    print(csvFileName+ \" will be preprocessed\")\n",
    "    data = pd.read_csv(csvFileName)\n",
    "    filenameArray = data['filename'] \n",
    "    speakerArray = []\n",
    "    #print(filenameArray)\n",
    "    for i in range(len(filenameArray)):\n",
    "        speaker = int(filenameArray[i].split(\"_\")[0].split(\"r\")[1])\n",
    "        if(speaker<61 or speaker==62):\n",
    "           speaker=0\n",
    "        else:\n",
    "           speaker=speaker-60\n",
    "        speakerArray.append(speaker)\n",
    "    data['number'] = speakerArray\n",
    "    #Dropping unnecessary columns\n",
    "    data = data.drop(['filename'],axis=1)\n",
    "    data = data.drop(['label'],axis=1)\n",
    "    data = data.drop(['chroma_stft'],axis=1)\n",
    "    data.shape\n",
    "\n",
    "    print(\"Preprocessing is finished\")\n",
    "    print(data.head())\n",
    "    return data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train.csv will be preprocessed\n",
      "Preprocessing is finished\n",
      "       rmse  spectral_centroid  spectral_bandwidth      rolloff  \\\n",
      "0  0.042311        2853.672685         2439.693251  5226.797861   \n",
      "1  0.066338        2483.207666         2219.299281  4473.985089   \n",
      "2  0.066239        1958.893779         1379.487170  3135.079496   \n",
      "3  0.028860        2084.254664         1733.049552  3707.682839   \n",
      "4  0.022163        2422.857641         2228.497802  4738.079083   \n",
      "\n",
      "   zero_crossing_rate       mfcc1       mfcc2      mfcc3      mfcc4  \\\n",
      "0            0.167396 -292.636353   77.443962 -14.946343   3.072196   \n",
      "1            0.149599 -293.354309   83.380547  17.072710  25.100824   \n",
      "2            0.133739 -279.818726  103.177750 -54.751225  26.485205   \n",
      "3            0.129757 -382.310455   98.181763  -7.513667  46.457611   \n",
      "4            0.111310 -434.465729   85.301010   6.917579  20.973516   \n",
      "\n",
      "       mfcc5  ...     mfcc12    mfcc13     mfcc14     mfcc15    mfcc16  \\\n",
      "0  -3.071160  ...  -3.540055 -8.385584  -2.319455 -12.365765 -4.030281   \n",
      "1   6.592123  ...  -2.588181 -6.496118   3.937195   0.163388 -7.575027   \n",
      "2 -37.830944  ...  -8.553962  2.186339  -9.772887   2.542377 -7.588593   \n",
      "3 -17.648285  ... -10.963368 -1.755158  -6.028708   9.532285 -8.492807   \n",
      "4 -10.743447  ...   4.555594  2.866588  13.123366  -4.678288  4.763774   \n",
      "\n",
      "      mfcc17    mfcc18    mfcc19    mfcc20  number  \n",
      "0 -11.485299 -4.964794 -9.287416 -7.967569       0  \n",
      "1   3.461552 -4.860189 -2.904794 -1.460528       0  \n",
      "2  -5.285561  0.092695  1.653523  1.318971       0  \n",
      "3  -2.989509  1.256674 -4.570978 -4.476323       0  \n",
      "4  -0.593649  4.143730 -2.482920  0.808900       0  \n",
      "\n",
      "[5 rows x 26 columns]\n",
      "test.csv will be preprocessed\n",
      "Preprocessing is finished\n",
      "       rmse  spectral_centroid  spectral_bandwidth      rolloff  \\\n",
      "0  0.062827        1439.703341         1214.381890  2639.298104   \n",
      "1  0.002583        3101.659607         3001.014250  6890.625000   \n",
      "2  0.027512        2776.314634         2410.166318  4949.863882   \n",
      "3  0.043108        2590.467849         1644.633082  4275.717944   \n",
      "4  0.050082        2295.733891         2206.135832  4407.636843   \n",
      "\n",
      "   zero_crossing_rate       mfcc1       mfcc2      mfcc3      mfcc4  \\\n",
      "0            0.078812 -318.895752  126.351379 -40.058258  38.671257   \n",
      "1            0.000000 -329.780945   82.097717  -8.962372  -2.279690   \n",
      "2            0.153912 -383.571259   76.857826   8.652615  27.628531   \n",
      "3            0.179322 -327.708710   86.886497 -55.782768  58.850853   \n",
      "4            0.113468 -324.181793   84.394577   4.927899  28.485275   \n",
      "\n",
      "       mfcc5  ...    mfcc12    mfcc13    mfcc14    mfcc15     mfcc16  \\\n",
      "0  -3.313738  ...  1.415402 -0.147205 -9.156339  6.357989  -2.505748   \n",
      "1  -4.091257  ... -0.116679  4.879228 -6.856781  6.554109  -5.191103   \n",
      "2  30.849646  ... -1.381173  0.096775  4.544846 -8.058209  12.572011   \n",
      "3 -19.301439  ... -9.678400  7.193476 -1.746455  5.566185 -19.890446   \n",
      "4   5.117252  ...  0.052406  7.227403  0.621997  0.836419   2.999624   \n",
      "\n",
      "      mfcc17     mfcc18    mfcc19    mfcc20  number  \n",
      "0  -3.565483   1.857242  1.661271 -2.067927       0  \n",
      "1   2.929139   0.088688 -3.295555  5.539860       0  \n",
      "2  -9.302295  10.571730 -2.299384  5.761469       0  \n",
      "3  15.223437  -6.382392 -5.325187  2.021258       0  \n",
      "4  -2.750336  -3.254150 -5.791872 -1.653584       0  \n",
      "\n",
      "[5 rows x 26 columns]\n",
      "           rmse  spectral_centroid  spectral_bandwidth      rolloff  \\\n",
      "0      0.042311        2853.672685         2439.693251  5226.797861   \n",
      "1      0.066338        2483.207666         2219.299281  4473.985089   \n",
      "2      0.066239        1958.893779         1379.487170  3135.079496   \n",
      "3      0.028860        2084.254664         1733.049552  3707.682839   \n",
      "4      0.022163        2422.857641         2228.497802  4738.079083   \n",
      "...         ...                ...                 ...          ...   \n",
      "14143  0.005392         779.615095          878.169638  1224.079778   \n",
      "14144  0.018871        1691.782026         2027.592719  3476.837909   \n",
      "14145  0.054073        1817.660463         1491.925403  3309.968075   \n",
      "14146  0.027263        2166.674470         2484.360333  4684.520861   \n",
      "14147  0.062758        1895.866736         1514.010588  3268.250616   \n",
      "\n",
      "       zero_crossing_rate       mfcc1       mfcc2      mfcc3      mfcc4  \\\n",
      "0                0.167396 -292.636353   77.443962 -14.946343   3.072196   \n",
      "1                0.149599 -293.354309   83.380547  17.072710  25.100824   \n",
      "2                0.133739 -279.818726  103.177750 -54.751225  26.485205   \n",
      "3                0.129757 -382.310455   98.181763  -7.513667  46.457611   \n",
      "4                0.111310 -434.465729   85.301010   6.917579  20.973516   \n",
      "...                   ...         ...         ...        ...        ...   \n",
      "14143            0.041541 -576.872498  227.872528 -26.166767   6.060908   \n",
      "14144            0.058969 -460.158783  108.104347   0.535474  14.185524   \n",
      "14145            0.117352 -302.880859   97.984131 -35.721714  44.873985   \n",
      "14146            0.089275 -415.691986  102.601639  21.565409  25.313324   \n",
      "14147            0.120337 -297.759094   96.225800 -51.321182  29.129894   \n",
      "\n",
      "           mfcc5  ...     mfcc12    mfcc13     mfcc14     mfcc15     mfcc16  \\\n",
      "0      -3.071160  ...  -3.540055 -8.385584  -2.319455 -12.365765  -4.030281   \n",
      "1       6.592123  ...  -2.588181 -6.496118   3.937195   0.163388  -7.575027   \n",
      "2     -37.830944  ...  -8.553962  2.186339  -9.772887   2.542377  -7.588593   \n",
      "3     -17.648285  ... -10.963368 -1.755158  -6.028708   9.532285  -8.492807   \n",
      "4     -10.743447  ...   4.555594  2.866588  13.123366  -4.678288   4.763774   \n",
      "...          ...  ...        ...       ...        ...        ...        ...   \n",
      "14143   4.554101  ... -20.250488  3.450274  -5.087423 -11.119873  10.245070   \n",
      "14144   0.065138  ...   4.104683  4.194519   5.587973  -0.820831   1.783475   \n",
      "14145  -3.822718  ... -12.290429 -1.314155 -12.242158   5.327736  -8.628503   \n",
      "14146  15.465093  ...  -5.792818 -2.786327  12.130173  -5.946178   8.095125   \n",
      "14147 -23.738693  ...  -8.653434  5.697582 -14.185470   0.323917  -0.744718   \n",
      "\n",
      "          mfcc17     mfcc18    mfcc19     mfcc20  number  \n",
      "0     -11.485299  -4.964794 -9.287416  -7.967569       0  \n",
      "1       3.461552  -4.860189 -2.904794  -1.460528       0  \n",
      "2      -5.285561   0.092695  1.653523   1.318971       0  \n",
      "3      -2.989509   1.256674 -4.570978  -4.476323       0  \n",
      "4      -0.593649   4.143730 -2.482920   0.808900       0  \n",
      "...          ...        ...       ...        ...     ...  \n",
      "14143  -2.047974 -12.681615 -0.286044 -12.103877       0  \n",
      "14144   4.656969   1.200366  0.396404   2.889664       0  \n",
      "14145  -7.799294   3.858961 -5.600139  -4.835082       0  \n",
      "14146  -3.184679  -0.492859 -3.623877  -0.291753       0  \n",
      "14147  -7.932398  -6.342644 -2.181794  -0.189857       0  \n",
      "\n",
      "[14148 rows x 26 columns]\n"
     ]
    }
   ],
   "source": [
    "trainData = preProcessData(TRAIN_CSV_FILE)\n",
    "\n",
    "testData = preProcessData(TEST_CSV_FILE)\n",
    "pd.DataFrame(trainData).to_parquet(\"train.parquet\")\n",
    "pd.DataFrame(testData).to_parquet(\"test.parquet\")\n",
    "print(trainData)\n",
    "#print(testData.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0, 1}\n",
      "Y from training data: (9903,)\n",
      "Y from validation data: (4245,)\n",
      "Y from test data: (3586,)\n"
     ]
    }
   ],
   "source": [
    "# Splitting the dataset into training, validation and testing dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "X = np.array(trainData.iloc[:, :-1], dtype = float)\n",
    "y = trainData.iloc[:, -1]\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, random_state=50)\n",
    "\n",
    "\n",
    "X_test = np.array(testData.iloc[:, :-1], dtype = float)\n",
    "y_test = testData.iloc[:, -1]\n",
    "print(set(y_train))\n",
    "\n",
    "print(\"Y from training data:\", y_train.shape)\n",
    "print(\"Y from validation data:\", y_val.shape)\n",
    "print(\"Y from test data:\", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X from training data (9903, 25)\n",
      "X from validation data (4245, 25)\n",
      "X from test data (3586, 25)\n"
     ]
    }
   ],
   "source": [
    "#Normalizing the dataset\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform( X_train )\n",
    "X_val = scaler.transform( X_val )\n",
    "X_test = scaler.transform( X_test )\n",
    "\n",
    "print(\"X from training data\", X_train.shape)\n",
    "print(\"X from validation data\", X_val.shape)\n",
    "print(\"X from test data\", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8813     0\n",
      "6886     0\n",
      "13549    0\n",
      "9965     0\n",
      "12232    0\n",
      "        ..\n",
      "10206    0\n",
      "6253     0\n",
      "10123    0\n",
      "5600     0\n",
      "14000    0\n",
      "Name: number, Length: 9903, dtype: int64]\n"
     ]
    }
   ],
   "source": [
    "print([y_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9903, 25)\n",
      "(9903,)\n",
      "(9903, 26)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "test=np.concatenate([X_train, np.array(y_train).reshape((len(y_train), 1))], axis = 1)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of values: 3272\n",
      "{0: 3242, 1: 15, 2: 15}\n",
      "{0: 0.00916870415647919, 1: 0.9954156479217604, 2: 0.9954156479217604}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import fnmatch\n",
    "import collections\n",
    "weight={}\n",
    "total=0\n",
    "path='audios/audios/56_speakers_audio_data'\n",
    "for speaker in os.listdir(path):\n",
    "    if speaker.find(\".sh\")==-1:\n",
    "        dir_path=path+'/'+speaker\n",
    "        speaker = int(speaker.split(\"_\")[0].split(\"r\")[1])\n",
    "        if(speaker<=60):\n",
    "            speaker = 0\n",
    "            total = total+int(len(fnmatch.filter(os.listdir(dir_path), '*.*'))*0.8)-1\n",
    "\n",
    "        else:\n",
    "            speaker= speaker-60\n",
    "        count = int(len(fnmatch.filter(os.listdir(dir_path), '*.*'))*0.8)-1\n",
    "        weight.update({speaker: count})\n",
    "weight.update({0:total})\n",
    "max_value=sum(weight.values())\n",
    "print(\"Sum of values: \"+str(max_value))\n",
    "weight = {key: value for key, value in sorted(weight.items())}\n",
    "print(weight)\n",
    "class_weight = {k: 1-(v/max_value) for k, v in weight.items()}\n",
    "print(class_weight)\n",
    "#print(set(range(57)) - set(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dump (parquet--> data train and test)\n",
    "scaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "weight={0:15, 1:42}\n",
    "\n",
    "max_value=sum(weight.values())\n",
    "print(\"Sum of values: \"+str(max_value))\n",
    "weight = {key: value for key, value in sorted(weight.items())}\n",
    "print(weight)\n",
    "class_weight = {k: (1-(v/max_value))*100 for k, v in weight.items()}\n",
    "print(class_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-09 13:35:30.056282: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-04-09 13:35:30.056302: W tensorflow/stream_executor/cuda/cuda_driver.cc:263] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-04-09 13:35:30.056318: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (silvia-XPS-15-9500): /proc/driver/nvidia/version does not exist\n",
      "2023-04-09 13:35:30.056532: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9903, 25)\n",
      "Epoch 1/100\n",
      "78/78 [==============================] - 1s 11ms/step - loss: 0.0742 - accuracy: 0.8445 - val_loss: 2.1574 - val_accuracy: 0.9986\n",
      "Epoch 2/100\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.0146 - accuracy: 0.9990 - val_loss: 0.0302 - val_accuracy: 0.9986\n",
      "Epoch 3/100\n",
      "78/78 [==============================] - 1s 10ms/step - loss: 0.0083 - accuracy: 0.9990 - val_loss: 0.0152 - val_accuracy: 0.9986\n",
      "Epoch 4/100\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.0057 - accuracy: 0.9990 - val_loss: 0.0105 - val_accuracy: 0.9986\n",
      "Epoch 5/100\n",
      "78/78 [==============================] - 1s 10ms/step - loss: 0.0034 - accuracy: 0.9990 - val_loss: 0.0140 - val_accuracy: 0.9986\n",
      "Epoch 6/100\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.0024 - accuracy: 0.9979 - val_loss: 0.0202 - val_accuracy: 0.9986\n",
      "Epoch 7/100\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.0022 - accuracy: 0.9976 - val_loss: 0.0151 - val_accuracy: 0.9986\n",
      "Epoch 8/100\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.0025 - accuracy: 0.9966 - val_loss: 0.0098 - val_accuracy: 0.9986\n",
      "Epoch 9/100\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.0020 - accuracy: 0.9903 - val_loss: 0.0158 - val_accuracy: 0.9991\n",
      "Epoch 10/100\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0013 - accuracy: 0.9871 - val_loss: 0.0059 - val_accuracy: 0.9988\n",
      "Epoch 11/100\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 9.4716e-04 - accuracy: 0.9912 - val_loss: 0.0040 - val_accuracy: 0.9993\n",
      "Epoch 12/100\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.0011 - accuracy: 0.9901 - val_loss: 0.0044 - val_accuracy: 0.9998\n",
      "Epoch 13/100\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.0011 - accuracy: 0.9871 - val_loss: 0.0025 - val_accuracy: 0.9998\n",
      "Epoch 14/100\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.0017 - accuracy: 0.9902 - val_loss: 0.0051 - val_accuracy: 1.0000\n",
      "Epoch 15/100\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 8.5032e-04 - accuracy: 0.9888 - val_loss: 0.0037 - val_accuracy: 1.0000\n",
      "Epoch 16/100\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 7.2066e-04 - accuracy: 0.9864 - val_loss: 0.0015 - val_accuracy: 0.9998\n",
      "Epoch 17/100\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.0013 - accuracy: 0.9881 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
      "Epoch 18/100\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 9.4200e-04 - accuracy: 0.9840 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
      "Epoch 19/100\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 9.9281e-04 - accuracy: 0.9902 - val_loss: 0.0012 - val_accuracy: 0.9998\n",
      "Epoch 20/100\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 3.1297e-04 - accuracy: 0.9922 - val_loss: 8.3807e-04 - val_accuracy: 0.9998\n",
      "Epoch 21/100\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 5.1217e-04 - accuracy: 0.9932 - val_loss: 8.3140e-04 - val_accuracy: 1.0000\n",
      "Epoch 22/100\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 6.9181e-04 - accuracy: 0.9902 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
      "Epoch 23/100\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 7.3164e-04 - accuracy: 0.9904 - val_loss: 7.5874e-04 - val_accuracy: 1.0000\n",
      "Epoch 24/100\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 3.5617e-04 - accuracy: 0.9922 - val_loss: 4.8857e-04 - val_accuracy: 1.0000\n",
      "Epoch 24: early stopping\n",
      "{0, 1}\n"
     ]
    }
   ],
   "source": [
    "#Creating a Model\n",
    "from keras import models\n",
    "from keras import layers\n",
    "import keras\n",
    "\n",
    "# model 1\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(32, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(32, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(len(y_train), activation='softmax'))\n",
    "\n",
    "# Learning Process of a model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# simple early stopping\n",
    "from keras.callbacks import EarlyStopping\n",
    "es = EarlyStopping(monitor='val_accuracy', patience=10, verbose=1)\n",
    "#es = EarlyStopping(monitor='val_loss', patience=3, verbose=1)\n",
    "print(X_train.shape)\n",
    "#Train with early stopping to avoid overfitting\n",
    "y_train=np.array(y_train, dtype=int)\n",
    "y_val=np.array(y_val, dtype=int)\n",
    "history = model.fit(X_train,y_train,validation_data=(X_val, y_val),epochs=100,batch_size=128, class_weight=class_weight, callbacks=[es])\n",
    "print(set(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 32)                832       \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 32)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                1056      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 9903)              326799    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 328,687\n",
      "Trainable params: 328,687\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot training history\n",
    "from matplotlib import pyplot\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSpeaker(speaker):\n",
    "    speaker = \"Speaker\"+str(speaker).zfill(3)\n",
    "    return speaker\n",
    "    \n",
    "        \n",
    "def printPrediction(X_data, y_data, printDigit, model):\n",
    "    print('\\n# Generate predictions')\n",
    "    for i in range(len(y_data)):\n",
    "        predict_x=model.predict(X_data[i:i+1])[0]\n",
    "        predict_classes = np.argmax(predict_x)\n",
    "        print(predict_classes)\n",
    "        print(max(predict_x))\n",
    "        prediction = getSpeaker(predict_classes)\n",
    "    \n",
    "        speaker = getSpeaker(y_data[i])\n",
    "        if printDigit == True:\n",
    "           print(\"Number={0:d}, y={1:10s}- prediction={2:10s}- match={3}\".format(i, speaker, prediction, speaker==prediction))\n",
    "        else:\n",
    "           print(\"y={0:10s}- prediction={1:10s}- match={2}\".format(speaker, prediction, speaker==prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "def report(X_data, y_data):\n",
    "    #Confution Matrix and Classification Report\n",
    "    predict_y = model.predict(X_data)\n",
    "    Y_pred = np.argmax(predict_y, axis=1)\n",
    "    y_test_num = y_data.astype(np.int64)\n",
    "    conf_mt = confusion_matrix(y_test_num, Y_pred)\n",
    "    print(conf_mt[len(set(y_test_num))-1])\n",
    "    key=0\n",
    "    for val in conf_mt[len(set(y_test_num))-1]:\n",
    "        if val!=0:\n",
    "            print(key)\n",
    "        key=key+1\n",
    "    conf_mt=conf_mt / conf_mt.astype(np.float).sum(axis=1)\n",
    "    #print(conf_mt)\n",
    "    plt.matshow(conf_mt)\n",
    "    plt.show()\n",
    "    print('\\nClassification Report')\n",
    "    print(classification_report(y_test_num, Y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0\n",
      "1       0\n",
      "2       0\n",
      "3       0\n",
      "4       0\n",
      "       ..\n",
      "3581    0\n",
      "3582    0\n",
      "3583    0\n",
      "3584    0\n",
      "3585    0\n",
      "Name: number, Length: 3586, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# TEST DATA #\n",
      "\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.1004 - accuracy: 0.9939\n",
      "accuracy: 99.39%\n"
     ]
    }
   ],
   "source": [
    "print('\\n# TEST DATA #\\n')\n",
    "y_test=np.array(y_test, dtype=int)\n",
    "score = model.evaluate(X_test, y_test)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], score[1]*100))\n",
    "# Prediction\n",
    "#printPrediction(X_test, y_test, False, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for Test Data\n",
      "\n",
      "(3586,)\n",
      "(3586, 25)\n",
      "113/113 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-09 13:35:48.220705: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 142048632 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20  4]\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 480x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      3562\n",
      "           1       0.67      0.17      0.27        24\n",
      "\n",
      "    accuracy                           0.99      3586\n",
      "   macro avg       0.83      0.58      0.63      3586\n",
      "weighted avg       0.99      0.99      0.99      3586\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification Report for Test Data\\n\")\n",
    "print(y_test.shape)\n",
    "print(X_test.shape)\n",
    "report(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['scaler.save']"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "model.save('speaker-recognition.h5')\n",
    "joblib.dump(scaler, 'scaler.save') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Transfer learning\n",
    "\n",
    "https://keras.io/guides/transfer_learning/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "def preProcessData(csvFileName):\n",
    "    data = pd.read_csv(csvFileName)\n",
    "    filenameArray = data['filename'] \n",
    "    speakerArray = []\n",
    "    #print(filenameArray)\n",
    "    for i in range(len(filenameArray)):\n",
    "        speaker = int(filenameArray[i].split(\"_\")[0].split(\"r\")[1])\n",
    "        speakerArray.append(speaker)\n",
    "    data['number'] = speakerArray\n",
    "    #Dropping unnecessary columns\n",
    "    data = data.drop(['filename'],axis=1)\n",
    "    data = data.drop(['label'],axis=1)\n",
    "    data = data.drop(['chroma_stft'],axis=1)\n",
    "    data.shape\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def getSpeaker(speaker):\n",
    "    speaker = \"Speaker\"+str(speaker).zfill(3)\n",
    "    return speaker\n",
    "    \n",
    "        \n",
    "def printPrediction(X_data, y_data, printDigit, model):\n",
    "    print('\\n# Generate predictions')\n",
    "    for i in range(len(y_data)):\n",
    "        predict_x=model.predict(X_data[i:i+1])[0]\n",
    "        predict_classes = np.argmax(predict_x)\n",
    "        prediction = getSpeaker(predict_classes)\n",
    "    \n",
    "        speaker = getSpeaker(y_data[i])\n",
    "        if printDigit == True:\n",
    "           print(\"Number={0:d}, y={1:10s}- prediction={2:10s}- match={3}\".format(i, speaker, prediction, speaker==prediction))\n",
    "        else:\n",
    "           print(\"y={0:10s}- prediction={1:10s}- match={2}\".format(speaker, prediction, speaker==prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractWavFeatures(filename, csvFileName):\n",
    "    header = 'filename chroma_stft rmse spectral_centroid spectral_bandwidth rolloff zero_crossing_rate'\n",
    "    for i in range(1, 21):\n",
    "        header += f' mfcc{i}'\n",
    "    header += ' label'\n",
    "    header = header.split()\n",
    "    file = open(csvFileName, 'w', newline='')\n",
    "    #with file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(header)\n",
    "    number = f'new_audios/test_file/{filename}'\n",
    "    y, sr = librosa.load(number, mono=True, duration=30)\n",
    "    # remove leading and trailing silence\n",
    "    y, index = librosa.effects.trim(y)\n",
    "    chroma_stft = librosa.feature.chroma_stft(y=y, sr=sr)\n",
    "    rmse = librosa.feature.rms(y=y)\n",
    "    spec_cent = librosa.feature.spectral_centroid(y=y, sr=sr)\n",
    "    spec_bw = librosa.feature.spectral_bandwidth(y=y, sr=sr)\n",
    "    rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr)\n",
    "    zcr = librosa.feature.zero_crossing_rate(y)\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr)\n",
    "    to_append = f'{filename} {np.mean(chroma_stft)} {np.mean(rmse)} {np.mean(spec_cent)} {np.mean(spec_bw)} {np.mean(rolloff)} {np.mean(zcr)}'\n",
    "    for e in mfcc:\n",
    "        to_append += f' {np.mean(e)}'\n",
    "    writer.writerow(to_append.split())\n",
    "    file.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_audio(filename):\n",
    "    extractWavFeatures(filename, final_test)\n",
    "    final_testData = preProcessData(final_test)\n",
    "    \n",
    "    X_test = np.array(final_testData.iloc[:, :-1], dtype = float)\n",
    "    y_test = final_testData.iloc[:, -1]\n",
    "    \n",
    "    X_test = scaler.transform( X_test )\n",
    "    #y_test=np.array(y_test, dtype=int)\n",
    "    \n",
    "    score = new_model.evaluate(X_test, y_test)\n",
    "    # Prediction\n",
    "    printPrediction(X_test, y_test, False, new_model)\n",
    "    print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final_test.csv will be preprocessed\n",
      "Preprocessing is finished\n",
      "       rmse  spectral_centroid  spectral_bandwidth      rolloff  \\\n",
      "0  0.007787        1842.464876         1743.385975  3579.227668   \n",
      "\n",
      "   zero_crossing_rate       mfcc1       mfcc2      mfcc3      mfcc4  \\\n",
      "0            0.107789 -444.994324  125.452003 -33.564625  43.520443   \n",
      "\n",
      "       mfcc5  ...     mfcc12    mfcc13   mfcc14    mfcc15    mfcc16    mfcc17  \\\n",
      "0 -27.101084  ... -11.397572  3.390763 -7.57964  9.951971 -2.636461  6.408022   \n",
      "\n",
      "     mfcc18    mfcc19    mfcc20  number  \n",
      "0 -6.711493  1.017713  2.169574      61  \n",
      "\n",
      "[1 rows x 26 columns]\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0753 - accuracy: 1.0000\n",
      "\n",
      "# Generate predictions\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "61\n",
      "0.9274281\n",
      "y=Speaker061- prediction=Speaker061- match=True\n",
      "0    61\n",
      "Name: number, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "import keras\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import librosa\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import csv\n",
    "\n",
    "\n",
    "final_test=\"final_test.csv\"\n",
    "new_model = keras.models.load_model('speaker-recognition.h5')\n",
    "scaler = joblib.load('scaler.save') \n",
    "\n",
    "predict_audio(\"Speaker0061_000.wav\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Register\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_CSV_FILE = \"train.csv\"\n",
    "NEW_USER = \"new_user.csv\"\n",
    "extractWavFeatures(\"new_audios/train\", NEW_USER)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataFrame = pd.read_csv(NEW_USER)\n",
    "dataFrame.to_csv(TRAIN_CSV_FILE, mode='a', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData = preProcessData(TRAIN_CSV_FILE)\n",
    "# Splitting the dataset into training, validation and testing dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "X = np.array(trainData.iloc[:, :-1], dtype = float)\n",
    "y = trainData.iloc[:, -1]\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, random_state=50)\n",
    "\n",
    "print(\"Y from training data:\", y_train.shape)\n",
    "print(\"Y from validation data:\", y_val.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalizing the dataset\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform( X_train )\n",
    "X_val = scaler.transform( X_val )\n",
    "\n",
    "print(\"X from training data\", X_train.shape)\n",
    "print(\"X from validation data\", X_val.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a Model\n",
    "from keras import models\n",
    "from keras import layers\n",
    "import keras\n",
    "\n",
    "# model 1\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(256, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(len(y_train), activation='softmax'))\n",
    "\n",
    "# Learning Process of a model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# simple early stopping\n",
    "from keras.callbacks import EarlyStopping\n",
    "#es = EarlyStopping(monitor='val_accuracy', patience=10, verbose=1)\n",
    "es = EarlyStopping(monitor='val_loss', patience=3, verbose=1)\n",
    "print(X_train.shape)\n",
    "#Train with early stopping to avoid overfitting\n",
    "y_train=np.array(y_train, dtype=int)\n",
    "y_val=np.array(y_val, dtype=int)\n",
    "history = model.fit(X_train,y_train,validation_data=(X_val, y_val),epochs=100,batch_size=1, callbacks=[es])\n",
    "print(set(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testData = preProcessData(TEST_CSV_FILE)\n",
    "\n",
    "X_test = np.array(testData.iloc[:, :-1], dtype = float)\n",
    "y_test = testData.iloc[:, -1]\n",
    "print(set(y_test))\n",
    "\n",
    "X_test = scaler.transform( X_test )\n",
    "print(\"X from test data\", X_test.shape)\n",
    "\n",
    "print(set(y_test))\n",
    "print(\"Y from test data:\", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n# TEST DATA #\\n')\n",
    "y_test=np.array(y_test, dtype=int)\n",
    "score = model.evaluate(X_test, y_test)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], score[1]*100))\n",
    "# Prediction\n",
    "printPrediction(X_test, y_test, False, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Classification Report for Test Data\\n\")\n",
    "print(y_test.shape)\n",
    "print(X_test.shape)\n",
    "report(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
