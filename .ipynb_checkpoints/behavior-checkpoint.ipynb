{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "0835a3d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1.csv', '3.csv', '4.csv', '2.csv', '7.csv', '6.csv', '0.csv', '5.csv']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "import fnmatch\n",
    "import collections\n",
    "import keras\n",
    "import librosa\n",
    "import csv\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras import models, layers\n",
    "from keras import backend as K\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from matplotlib import pyplot, cm\n",
    "from tqdm import tqdm\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "os.chdir (\"/home/silvia/Escritorio/tfm/Server_auth/behavior/1\")\n",
    "extension = 'csv'\n",
    "files=[i for i in glob.glob('*.{}'.format(extension))]\n",
    "print(files)\n",
    "user = pd.concat([pd.read_csv(f) for f in files])\n",
    "user=user.sample(frac=1).reset_index(drop=True)\n",
    "user=user.assign(user=1)\n",
    "user.to_csv(\"../user.csv\", index=False, encoding='utf-8-sig')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "0c07da0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_secs</th>\n",
       "      <th>scrolling</th>\n",
       "      <th>mouse_clicks</th>\n",
       "      <th>e_legend_clicks</th>\n",
       "      <th>e_map_clicks</th>\n",
       "      <th>map_clicks</th>\n",
       "      <th>general_clicks</th>\n",
       "      <th>close_top_clicks</th>\n",
       "      <th>close_bottom_clicks</th>\n",
       "      <th>go_clicks</th>\n",
       "      <th>map_zoom</th>\n",
       "      <th>mouse_mov</th>\n",
       "      <th>key_presses</th>\n",
       "      <th>priority</th>\n",
       "      <th>order</th>\n",
       "      <th>user</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.260000</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>30.600000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15</td>\n",
       "      <td>3.533333</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>45</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>23.200000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.257143</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27.742857</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.285714</td>\n",
       "      <td>38.800000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>25</td>\n",
       "      <td>2.120000</td>\n",
       "      <td>0.240000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26.720000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>30</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>125.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>125.000000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>38.800000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>30</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24.366667</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>15</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.866667</td>\n",
       "      <td>39.666667</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    time_secs  scrolling  mouse_clicks  e_legend_clicks  e_map_clicks  \\\n",
       "0          50   0.000000      0.260000         0.153846      0.307692   \n",
       "1          15   3.533333      0.200000         0.000000      0.333333   \n",
       "2          45   0.000000      0.222222         0.000000      0.500000   \n",
       "3          35   0.000000      0.257143         0.000000      0.555556   \n",
       "4          35   0.000000      0.285714         0.100000      0.400000   \n",
       "..        ...        ...           ...              ...           ...   \n",
       "70         25   2.120000      0.240000         0.000000      0.500000   \n",
       "71         30   0.000000      0.266667         0.000000      0.500000   \n",
       "72         30   0.000000      0.266667         0.000000      0.500000   \n",
       "73          5   0.000000      0.200000         1.000000      0.000000   \n",
       "74         15   0.000000      0.333333         0.000000      0.400000   \n",
       "\n",
       "    map_clicks  general_clicks  close_top_clicks  close_bottom_clicks  \\\n",
       "0     0.076923             0.0                 0             0.384615   \n",
       "1     0.333333             0.0                 0             0.333333   \n",
       "2     0.000000             0.0                 0             0.500000   \n",
       "3     0.000000             0.0                 0             0.444444   \n",
       "4     0.100000             0.0                 0             0.300000   \n",
       "..         ...             ...               ...                  ...   \n",
       "70    0.166667             0.0                 0             0.333333   \n",
       "71  125.000000             0.0                 0             0.250000   \n",
       "72    0.000000             0.0                 0             0.500000   \n",
       "73    0.000000             0.0                 0             0.000000   \n",
       "74    0.400000             0.0                 0             0.200000   \n",
       "\n",
       "     go_clicks  map_zoom  mouse_mov  key_presses  priority  order  user  \n",
       "0     0.076923  0.900000  30.600000            0         1      0     1  \n",
       "1     0.000000  0.000000  24.000000            0         1      1     1  \n",
       "2     0.000000  0.000000  23.200000            0         1      0     1  \n",
       "3     0.000000  0.000000  27.742857            0         1      0     1  \n",
       "4     0.100000  1.285714  38.800000            0         1      0     1  \n",
       "..         ...       ...        ...          ...       ...    ...   ...  \n",
       "70    0.000000  0.000000  26.720000            0         1      1     1  \n",
       "71  125.000000  1.500000  38.800000            0         1      0     1  \n",
       "72    0.000000  0.000000  24.366667            0         1      0     1  \n",
       "73    0.000000  0.000000  18.000000            0         1      1     1  \n",
       "74    0.000000  1.866667  39.666667            0         1      0     1  \n",
       "\n",
       "[75 rows x 16 columns]"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c147d86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60\n"
     ]
    }
   ],
   "source": [
    "size= int(len(user.index)*0.8)\n",
    "print(size)\n",
    "user_train=user.iloc[:size, :]\n",
    "user_test=user.iloc[size:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "2488ec2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['15.csv', '17.csv', '18.csv', '10.csv', '13.csv', '14.csv', '16.csv', '11.csv', '8.csv', '19.csv', '9.csv', '12.csv']\n"
     ]
    }
   ],
   "source": [
    "os.chdir (\"/home/silvia/Escritorio/tfm/Server_auth/behavior/0\")\n",
    "extension = 'csv'\n",
    "files=[i for i in glob.glob('*.{}'.format(extension))]\n",
    "print(files)\n",
    "nouser = pd.concat([pd.read_csv(f) for f in files])\n",
    "nouser=nouser.sample(frac=1).reset_index(drop=True)\n",
    "nouser=nouser.assign(user=0)\n",
    "nouser.to_csv(\"../nouser.csv\", index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "caaa77a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_secs</th>\n",
       "      <th>scrolling</th>\n",
       "      <th>mouse_clicks</th>\n",
       "      <th>e_legend_clicks</th>\n",
       "      <th>e_map_clicks</th>\n",
       "      <th>map_clicks</th>\n",
       "      <th>general_clicks</th>\n",
       "      <th>close_top_clicks</th>\n",
       "      <th>close_bottom_clicks</th>\n",
       "      <th>go_clicks</th>\n",
       "      <th>map_zoom</th>\n",
       "      <th>mouse_mov</th>\n",
       "      <th>key_presses</th>\n",
       "      <th>priority</th>\n",
       "      <th>order</th>\n",
       "      <th>user</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.586207</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>65.103448</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>40</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.178571</td>\n",
       "      <td>0.178571</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0</td>\n",
       "      <td>0.178571</td>\n",
       "      <td>0.178571</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>59.925000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>2.933333</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>61.266667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>32.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>30</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27.700000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>10</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>50.400000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>30</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.833333</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>39</td>\n",
       "      <td>1.692308</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>15.589744</td>\n",
       "      <td>27.128205</td>\n",
       "      <td>0.358974</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>99 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    time_secs  scrolling  mouse_clicks  e_legend_clicks  e_map_clicks  \\\n",
       "0          29   0.000000      0.586207         0.000000      0.470588   \n",
       "1          40   0.000000      0.700000         0.178571      0.178571   \n",
       "2          15   0.000000      0.000000         0.000000      0.000000   \n",
       "3          15   2.933333      0.600000         0.000000      0.444444   \n",
       "4          15   0.000000      0.400000         0.500000      0.000000   \n",
       "..        ...        ...           ...              ...           ...   \n",
       "94         30   0.000000      0.333333         0.500000      0.000000   \n",
       "95         10   0.400000      0.500000         0.600000      0.000000   \n",
       "96          5   0.000000      0.400000         0.500000      0.000000   \n",
       "97         30   0.000000      0.533333         0.312500      0.187500   \n",
       "98         39   1.692308      0.333333         0.000000      0.307692   \n",
       "\n",
       "    map_clicks  general_clicks  close_top_clicks  close_bottom_clicks  \\\n",
       "0     0.058824               0          0.235294             0.000000   \n",
       "1     0.285714               0          0.178571             0.178571   \n",
       "2     0.000000               0          0.000000             0.000000   \n",
       "3     0.111111               0          0.111111             0.333333   \n",
       "4     0.000000               0          0.500000             0.000000   \n",
       "..         ...             ...               ...                  ...   \n",
       "94    0.000000               0          0.500000             0.000000   \n",
       "95    0.000000               0          0.400000             0.000000   \n",
       "96    0.000000               0          0.500000             0.000000   \n",
       "97    0.000000               0          0.000000             0.500000   \n",
       "98    0.384615               0          0.000000             0.076923   \n",
       "\n",
       "    go_clicks   map_zoom  mouse_mov  key_presses  priority  order  user  \n",
       "0    0.235294   0.000000  65.103448     0.000000         0      0     0  \n",
       "1    0.000000   1.500000  59.925000     0.000000         1      1     0  \n",
       "2    0.000000   0.000000   0.000000     0.000000         1      1     0  \n",
       "3    0.000000   0.000000  61.266667     0.000000         1      0     0  \n",
       "4    0.000000   0.000000  32.333333     0.000000         1      1     0  \n",
       "..        ...        ...        ...          ...       ...    ...   ...  \n",
       "94   0.000000   0.000000  27.700000     0.000000         1      1     0  \n",
       "95   0.000000   0.000000  50.400000     0.000000         1      1     0  \n",
       "96   0.000000   0.000000  40.000000     0.000000         1      1     0  \n",
       "97   0.000000   0.000000  30.833333     0.066667         0      0     0  \n",
       "98   0.230769  15.589744  27.128205     0.358974         0      0     0  \n",
       "\n",
       "[99 rows x 16 columns]"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nouser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "024851d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79\n"
     ]
    }
   ],
   "source": [
    "size= int(len(nouser.index)*0.8)\n",
    "\n",
    "print(size)\n",
    "nouser_train=nouser.iloc[:size, :]\n",
    "nouser_test=nouser.iloc[size:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702ba06d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "02fd8d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames=[nouser_train, user_train]\n",
    "train=pd.concat(frames)\n",
    "frames=[nouser_test, user_test]\n",
    "test=pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "8a35d391",
   "metadata": {},
   "outputs": [],
   "source": [
    "testData=test.drop(columns='time_secs')\n",
    "trainData=train.drop(columns='time_secs')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "5826d3e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0, 1}\n",
      "Y from training data: (97,)\n",
      "Y from validation data: (42,)\n",
      "Y from test data: (35,)\n"
     ]
    }
   ],
   "source": [
    "# Splitting the dataset into training, validation and testing dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "X = np.array(trainData.iloc[:, :-1], dtype = float)\n",
    "y = trainData.iloc[:, -1]\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, random_state=50)\n",
    "\n",
    "\n",
    "X_test = np.array(testData.iloc[:, :-1], dtype = float)\n",
    "y_test = testData.iloc[:, -1]\n",
    "print(set(y_train))\n",
    "\n",
    "print(\"Y from training data:\", y_train.shape)\n",
    "print(\"Y from validation data:\", y_val.shape)\n",
    "print(\"Y from test data:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "ed29c4af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X from training data (97, 14)\n",
      "X from validation data (42, 14)\n",
      "X from test data (35, 14)\n",
      "{0, 1}\n"
     ]
    }
   ],
   "source": [
    "#Normalizing the dataset\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform( X_train )\n",
    "X_val = scaler.transform( X_val )\n",
    "X_test = scaler.transform( X_test )\n",
    "\n",
    "print(\"X from training data\", X_train.shape)\n",
    "print(\"X from validation data\", X_val.shape)\n",
    "print(\"X from test data\", X_test.shape)\n",
    "\n",
    "print(set(y_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "05f689f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of values: 174\n",
      "{0: 99, 1: 75}\n",
      "{0: 0.43103448275862066, 1: 0.5689655172413793}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import fnmatch\n",
    "import collections\n",
    "weight={}\n",
    "path='audios/audios/56_speakers_audio_data'\n",
    "weight.update({0: len(nouser.index), 1: len(user.index)})\n",
    "max_value=sum(weight.values())\n",
    "print(\"Sum of values: \"+str(max_value))\n",
    "weight = {key: value for key, value in sorted(weight.items())}\n",
    "print(weight)\n",
    "class_weight = {k: 1-(v/max_value) for k, v in weight.items()}\n",
    "print(class_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "f5daffb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(97, 14)\n",
      "Epoch 1/200\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 4.6081 - accuracy: 0.0103 - val_loss: 4.4681 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 4.4777 - accuracy: 0.0412 - val_loss: 4.3599 - val_accuracy: 0.1429\n",
      "Epoch 3/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 4.3820 - accuracy: 0.0412 - val_loss: 4.2476 - val_accuracy: 0.3571\n",
      "Epoch 4/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 4.2457 - accuracy: 0.0825 - val_loss: 4.1231 - val_accuracy: 0.6429\n",
      "Epoch 5/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 4.0341 - accuracy: 0.1649 - val_loss: 3.9786 - val_accuracy: 0.7857\n",
      "Epoch 6/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.9488 - accuracy: 0.2990 - val_loss: 3.8082 - val_accuracy: 0.8095\n",
      "Epoch 7/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 3.7943 - accuracy: 0.3093 - val_loss: 3.6087 - val_accuracy: 0.8333\n",
      "Epoch 8/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.6553 - accuracy: 0.3505 - val_loss: 3.3744 - val_accuracy: 0.8333\n",
      "Epoch 9/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 3.3830 - accuracy: 0.4330 - val_loss: 3.0973 - val_accuracy: 0.8333\n",
      "Epoch 10/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.1243 - accuracy: 0.4948 - val_loss: 2.7675 - val_accuracy: 0.8333\n",
      "Epoch 11/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 2.5973 - accuracy: 0.6289 - val_loss: 2.3817 - val_accuracy: 0.8333\n",
      "Epoch 12/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 2.3151 - accuracy: 0.6701 - val_loss: 1.9485 - val_accuracy: 0.8333\n",
      "Epoch 13/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 2.2518 - accuracy: 0.5464 - val_loss: 1.5116 - val_accuracy: 0.8333\n",
      "Epoch 14/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.8764 - accuracy: 0.6082 - val_loss: 1.1223 - val_accuracy: 0.8333\n",
      "Epoch 15/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.4933 - accuracy: 0.6598 - val_loss: 0.8360 - val_accuracy: 0.8333\n",
      "Epoch 16/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.3093 - accuracy: 0.6701 - val_loss: 0.6547 - val_accuracy: 0.8333\n",
      "Epoch 17/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.0425 - accuracy: 0.6701 - val_loss: 0.5500 - val_accuracy: 0.8333\n",
      "Epoch 18/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.0927 - accuracy: 0.7010 - val_loss: 0.4946 - val_accuracy: 0.7857\n",
      "Epoch 19/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.9339 - accuracy: 0.6186 - val_loss: 0.4671 - val_accuracy: 0.7857\n",
      "Epoch 20/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.6819 - accuracy: 0.7938 - val_loss: 0.4521 - val_accuracy: 0.7619\n",
      "Epoch 21/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.7801 - accuracy: 0.7010 - val_loss: 0.4391 - val_accuracy: 0.7619\n",
      "Epoch 22/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7901 - accuracy: 0.6186 - val_loss: 0.4327 - val_accuracy: 0.7381\n",
      "Epoch 23/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.7826 - accuracy: 0.7113 - val_loss: 0.4301 - val_accuracy: 0.7381\n",
      "Epoch 24/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.6825 - accuracy: 0.7216 - val_loss: 0.4190 - val_accuracy: 0.7381\n",
      "Epoch 25/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6912 - accuracy: 0.6907 - val_loss: 0.4074 - val_accuracy: 0.7619\n",
      "Epoch 26/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.6659 - accuracy: 0.7010 - val_loss: 0.4019 - val_accuracy: 0.7857\n",
      "Epoch 27/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7835 - accuracy: 0.7010 - val_loss: 0.4013 - val_accuracy: 0.7857\n",
      "Epoch 28/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7895 - accuracy: 0.7010 - val_loss: 0.4118 - val_accuracy: 0.8095\n",
      "Epoch 29/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7368 - accuracy: 0.7010 - val_loss: 0.4231 - val_accuracy: 0.8333\n",
      "Epoch 30/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7388 - accuracy: 0.7320 - val_loss: 0.4219 - val_accuracy: 0.8333\n",
      "Epoch 31/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5409 - accuracy: 0.7938 - val_loss: 0.4125 - val_accuracy: 0.8095\n",
      "Epoch 32/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7397 - accuracy: 0.7423 - val_loss: 0.3984 - val_accuracy: 0.7857\n",
      "Epoch 33/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5696 - accuracy: 0.7526 - val_loss: 0.3946 - val_accuracy: 0.7619\n",
      "Epoch 34/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5826 - accuracy: 0.7732 - val_loss: 0.3951 - val_accuracy: 0.7619\n",
      "Epoch 35/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.6235 - accuracy: 0.7216 - val_loss: 0.3979 - val_accuracy: 0.7619\n",
      "Epoch 36/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5127 - accuracy: 0.7835 - val_loss: 0.4040 - val_accuracy: 0.7619\n",
      "Epoch 37/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5159 - accuracy: 0.8144 - val_loss: 0.4058 - val_accuracy: 0.7619\n",
      "Epoch 38/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5644 - accuracy: 0.7010 - val_loss: 0.4036 - val_accuracy: 0.7619\n",
      "Epoch 39/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4600 - accuracy: 0.7938 - val_loss: 0.4032 - val_accuracy: 0.7619\n",
      "Epoch 40/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4785 - accuracy: 0.8351 - val_loss: 0.4032 - val_accuracy: 0.7619\n",
      "Epoch 41/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6336 - accuracy: 0.7526 - val_loss: 0.4032 - val_accuracy: 0.7619\n",
      "Epoch 42/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4381 - accuracy: 0.8144 - val_loss: 0.4034 - val_accuracy: 0.7619\n",
      "Epoch 43/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3736 - accuracy: 0.8454 - val_loss: 0.4031 - val_accuracy: 0.7619\n",
      "Epoch 44/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4943 - accuracy: 0.7835 - val_loss: 0.4028 - val_accuracy: 0.7619\n",
      "Epoch 45/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5319 - accuracy: 0.8041 - val_loss: 0.4030 - val_accuracy: 0.7619\n",
      "Epoch 46/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4066 - accuracy: 0.8041 - val_loss: 0.4027 - val_accuracy: 0.7619\n",
      "Epoch 47/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4198 - accuracy: 0.7629 - val_loss: 0.4044 - val_accuracy: 0.7619\n",
      "Epoch 48/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3943 - accuracy: 0.7732 - val_loss: 0.4074 - val_accuracy: 0.7619\n",
      "Epoch 49/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4354 - accuracy: 0.8144 - val_loss: 0.4085 - val_accuracy: 0.7619\n",
      "Epoch 50/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4343 - accuracy: 0.8144 - val_loss: 0.4082 - val_accuracy: 0.7619\n",
      "Epoch 51/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4561 - accuracy: 0.8247 - val_loss: 0.4075 - val_accuracy: 0.7619\n",
      "Epoch 52/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5624 - accuracy: 0.7526 - val_loss: 0.4060 - val_accuracy: 0.7619\n",
      "Epoch 53/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3982 - accuracy: 0.8454 - val_loss: 0.4061 - val_accuracy: 0.7619\n",
      "Epoch 54/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4384 - accuracy: 0.8041 - val_loss: 0.4076 - val_accuracy: 0.7619\n",
      "Epoch 55/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3784 - accuracy: 0.8454 - val_loss: 0.4076 - val_accuracy: 0.7619\n",
      "Epoch 56/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4512 - accuracy: 0.8041 - val_loss: 0.4062 - val_accuracy: 0.7619\n",
      "Epoch 57/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4132 - accuracy: 0.7938 - val_loss: 0.4043 - val_accuracy: 0.7619\n",
      "Epoch 58/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4227 - accuracy: 0.8351 - val_loss: 0.4030 - val_accuracy: 0.7619\n",
      "Epoch 59/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3454 - accuracy: 0.8763 - val_loss: 0.4034 - val_accuracy: 0.7619\n",
      "Epoch 60/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3508 - accuracy: 0.8247 - val_loss: 0.4043 - val_accuracy: 0.7619\n",
      "Epoch 61/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4293 - accuracy: 0.8041 - val_loss: 0.4061 - val_accuracy: 0.7619\n",
      "Epoch 62/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4277 - accuracy: 0.8557 - val_loss: 0.4081 - val_accuracy: 0.7619\n",
      "Epoch 63/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4798 - accuracy: 0.7938 - val_loss: 0.4102 - val_accuracy: 0.7619\n",
      "Epoch 64/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4337 - accuracy: 0.7835 - val_loss: 0.4099 - val_accuracy: 0.7619\n",
      "Epoch 65/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4489 - accuracy: 0.7629 - val_loss: 0.4070 - val_accuracy: 0.7619\n",
      "Epoch 66/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4148 - accuracy: 0.7938 - val_loss: 0.4027 - val_accuracy: 0.7619\n",
      "Epoch 67/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4374 - accuracy: 0.8041 - val_loss: 0.4003 - val_accuracy: 0.7619\n",
      "Epoch 68/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4408 - accuracy: 0.8454 - val_loss: 0.3987 - val_accuracy: 0.7619\n",
      "Epoch 69/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4730 - accuracy: 0.7732 - val_loss: 0.3982 - val_accuracy: 0.7619\n",
      "Epoch 70/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3090 - accuracy: 0.8454 - val_loss: 0.3948 - val_accuracy: 0.7619\n",
      "Epoch 71/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3315 - accuracy: 0.8351 - val_loss: 0.3893 - val_accuracy: 0.7619\n",
      "Epoch 72/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4884 - accuracy: 0.7732 - val_loss: 0.3852 - val_accuracy: 0.7619\n",
      "Epoch 73/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3587 - accuracy: 0.8454 - val_loss: 0.3864 - val_accuracy: 0.8095\n",
      "Epoch 74/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4207 - accuracy: 0.8351 - val_loss: 0.3866 - val_accuracy: 0.8095\n",
      "Epoch 75/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4076 - accuracy: 0.8247 - val_loss: 0.3824 - val_accuracy: 0.8095\n",
      "Epoch 76/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3584 - accuracy: 0.8247 - val_loss: 0.3798 - val_accuracy: 0.7619\n",
      "Epoch 77/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3390 - accuracy: 0.8557 - val_loss: 0.3811 - val_accuracy: 0.7619\n",
      "Epoch 78/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3290 - accuracy: 0.8557 - val_loss: 0.3804 - val_accuracy: 0.7619\n",
      "Epoch 79/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4155 - accuracy: 0.8454 - val_loss: 0.3785 - val_accuracy: 0.7619\n",
      "Epoch 80/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3784 - accuracy: 0.7835 - val_loss: 0.3756 - val_accuracy: 0.7619\n",
      "Epoch 81/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4683 - accuracy: 0.7835 - val_loss: 0.3742 - val_accuracy: 0.7857\n",
      "Epoch 82/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3608 - accuracy: 0.8557 - val_loss: 0.3741 - val_accuracy: 0.7857\n",
      "Epoch 83/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3894 - accuracy: 0.8351 - val_loss: 0.3747 - val_accuracy: 0.7857\n",
      "Epoch 84/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3601 - accuracy: 0.8557 - val_loss: 0.3754 - val_accuracy: 0.7857\n",
      "Epoch 85/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3592 - accuracy: 0.8557 - val_loss: 0.3763 - val_accuracy: 0.7857\n",
      "Epoch 86/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3737 - accuracy: 0.8041 - val_loss: 0.3781 - val_accuracy: 0.7619\n",
      "Epoch 87/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3339 - accuracy: 0.8557 - val_loss: 0.3801 - val_accuracy: 0.7619\n",
      "Epoch 88/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4046 - accuracy: 0.8041 - val_loss: 0.3812 - val_accuracy: 0.7619\n",
      "Epoch 89/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3580 - accuracy: 0.8247 - val_loss: 0.3802 - val_accuracy: 0.7619\n",
      "Epoch 90/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3608 - accuracy: 0.8763 - val_loss: 0.3785 - val_accuracy: 0.7619\n",
      "Epoch 91/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3679 - accuracy: 0.8041 - val_loss: 0.3777 - val_accuracy: 0.7857\n",
      "Epoch 92/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3798 - accuracy: 0.8454 - val_loss: 0.3777 - val_accuracy: 0.7857\n",
      "Epoch 93/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3423 - accuracy: 0.8247 - val_loss: 0.3776 - val_accuracy: 0.7857\n",
      "Epoch 94/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3653 - accuracy: 0.8041 - val_loss: 0.3772 - val_accuracy: 0.8095\n",
      "Epoch 95/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3967 - accuracy: 0.8454 - val_loss: 0.3788 - val_accuracy: 0.8095\n",
      "Epoch 96/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3699 - accuracy: 0.8247 - val_loss: 0.3800 - val_accuracy: 0.8095\n",
      "Epoch 97/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4264 - accuracy: 0.8041 - val_loss: 0.3799 - val_accuracy: 0.7619\n",
      "Epoch 98/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3688 - accuracy: 0.7938 - val_loss: 0.3791 - val_accuracy: 0.7619\n",
      "Epoch 99/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3474 - accuracy: 0.8041 - val_loss: 0.3785 - val_accuracy: 0.7619\n",
      "Epoch 100/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3303 - accuracy: 0.8144 - val_loss: 0.3781 - val_accuracy: 0.7619\n",
      "Epoch 101/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3301 - accuracy: 0.8351 - val_loss: 0.3791 - val_accuracy: 0.7619\n",
      "Epoch 102/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3697 - accuracy: 0.7835 - val_loss: 0.3797 - val_accuracy: 0.7619\n",
      "Epoch 103/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3174 - accuracy: 0.8247 - val_loss: 0.3782 - val_accuracy: 0.7619\n",
      "Epoch 104/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3241 - accuracy: 0.8351 - val_loss: 0.3759 - val_accuracy: 0.7619\n",
      "Epoch 105/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3784 - accuracy: 0.8557 - val_loss: 0.3744 - val_accuracy: 0.7619\n",
      "Epoch 106/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2850 - accuracy: 0.8660 - val_loss: 0.3724 - val_accuracy: 0.7619\n",
      "Epoch 107/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3329 - accuracy: 0.8351 - val_loss: 0.3713 - val_accuracy: 0.7619\n",
      "Epoch 108/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3872 - accuracy: 0.8351 - val_loss: 0.3702 - val_accuracy: 0.7619\n",
      "Epoch 109/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3289 - accuracy: 0.8454 - val_loss: 0.3696 - val_accuracy: 0.7619\n",
      "Epoch 110/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3282 - accuracy: 0.8454 - val_loss: 0.3708 - val_accuracy: 0.7619\n",
      "Epoch 111/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3294 - accuracy: 0.8660 - val_loss: 0.3708 - val_accuracy: 0.7619\n",
      "Epoch 112/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3141 - accuracy: 0.8557 - val_loss: 0.3700 - val_accuracy: 0.7619\n",
      "Epoch 113/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3406 - accuracy: 0.8144 - val_loss: 0.3695 - val_accuracy: 0.7619\n",
      "Epoch 114/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3268 - accuracy: 0.8557 - val_loss: 0.3708 - val_accuracy: 0.7619\n",
      "Epoch 115/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3743 - accuracy: 0.7938 - val_loss: 0.3720 - val_accuracy: 0.7619\n",
      "Epoch 116/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3502 - accuracy: 0.8144 - val_loss: 0.3703 - val_accuracy: 0.7619\n",
      "Epoch 117/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3252 - accuracy: 0.8557 - val_loss: 0.3666 - val_accuracy: 0.7619\n",
      "Epoch 118/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2861 - accuracy: 0.8557 - val_loss: 0.3651 - val_accuracy: 0.8095\n",
      "Epoch 119/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3203 - accuracy: 0.8144 - val_loss: 0.3648 - val_accuracy: 0.8095\n",
      "Epoch 120/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3106 - accuracy: 0.8247 - val_loss: 0.3648 - val_accuracy: 0.8333\n",
      "Epoch 121/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3466 - accuracy: 0.8144 - val_loss: 0.3650 - val_accuracy: 0.8333\n",
      "Epoch 122/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3365 - accuracy: 0.8144 - val_loss: 0.3640 - val_accuracy: 0.8333\n",
      "Epoch 123/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3193 - accuracy: 0.8247 - val_loss: 0.3631 - val_accuracy: 0.8333\n",
      "Epoch 124/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3297 - accuracy: 0.8454 - val_loss: 0.3636 - val_accuracy: 0.8333\n",
      "Epoch 125/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3017 - accuracy: 0.8144 - val_loss: 0.3640 - val_accuracy: 0.8333\n",
      "Epoch 126/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3237 - accuracy: 0.8866 - val_loss: 0.3636 - val_accuracy: 0.8095\n",
      "Epoch 127/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.2608 - accuracy: 0.8763 - val_loss: 0.3655 - val_accuracy: 0.7619\n",
      "Epoch 128/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3134 - accuracy: 0.8041 - val_loss: 0.3674 - val_accuracy: 0.7619\n",
      "Epoch 129/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3379 - accuracy: 0.8144 - val_loss: 0.3681 - val_accuracy: 0.7619\n",
      "Epoch 130/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3276 - accuracy: 0.8041 - val_loss: 0.3666 - val_accuracy: 0.7619\n",
      "Epoch 131/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3269 - accuracy: 0.8144 - val_loss: 0.3645 - val_accuracy: 0.7619\n",
      "Epoch 132/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2970 - accuracy: 0.8351 - val_loss: 0.3639 - val_accuracy: 0.7619\n",
      "Epoch 133/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3029 - accuracy: 0.8351 - val_loss: 0.3631 - val_accuracy: 0.7857\n",
      "Epoch 134/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3152 - accuracy: 0.8351 - val_loss: 0.3641 - val_accuracy: 0.7619\n",
      "Epoch 135/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2921 - accuracy: 0.8454 - val_loss: 0.3668 - val_accuracy: 0.7619\n",
      "Epoch 136/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3575 - accuracy: 0.8557 - val_loss: 0.3682 - val_accuracy: 0.7619\n",
      "Epoch 137/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.2851 - accuracy: 0.8866 - val_loss: 0.3694 - val_accuracy: 0.7619\n",
      "Epoch 138/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.2898 - accuracy: 0.8351 - val_loss: 0.3690 - val_accuracy: 0.7619\n",
      "Epoch 139/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3561 - accuracy: 0.8144 - val_loss: 0.3688 - val_accuracy: 0.7857\n",
      "Epoch 140/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3306 - accuracy: 0.8454 - val_loss: 0.3692 - val_accuracy: 0.8095\n",
      "Epoch 141/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3502 - accuracy: 0.8351 - val_loss: 0.3686 - val_accuracy: 0.8095\n",
      "Epoch 142/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3145 - accuracy: 0.8660 - val_loss: 0.3681 - val_accuracy: 0.7857\n",
      "Epoch 143/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2872 - accuracy: 0.8557 - val_loss: 0.3686 - val_accuracy: 0.7857\n",
      "Epoch 144/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2686 - accuracy: 0.8454 - val_loss: 0.3690 - val_accuracy: 0.8095\n",
      "Epoch 145/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.2750 - accuracy: 0.8454 - val_loss: 0.3692 - val_accuracy: 0.8095\n",
      "Epoch 146/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3611 - accuracy: 0.8351 - val_loss: 0.3705 - val_accuracy: 0.8333\n",
      "Epoch 147/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3493 - accuracy: 0.8247 - val_loss: 0.3749 - val_accuracy: 0.8333\n",
      "Epoch 148/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.2976 - accuracy: 0.8660 - val_loss: 0.3793 - val_accuracy: 0.8095\n",
      "Epoch 149/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3233 - accuracy: 0.8247 - val_loss: 0.3803 - val_accuracy: 0.8095\n",
      "Epoch 150/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2792 - accuracy: 0.8557 - val_loss: 0.3795 - val_accuracy: 0.7619\n",
      "Epoch 151/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3176 - accuracy: 0.8247 - val_loss: 0.3781 - val_accuracy: 0.7381\n",
      "Epoch 152/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2812 - accuracy: 0.8763 - val_loss: 0.3782 - val_accuracy: 0.7381\n",
      "Epoch 153/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2822 - accuracy: 0.8247 - val_loss: 0.3771 - val_accuracy: 0.7619\n",
      "Epoch 154/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3028 - accuracy: 0.8660 - val_loss: 0.3758 - val_accuracy: 0.7857\n",
      "Epoch 155/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3460 - accuracy: 0.7938 - val_loss: 0.3735 - val_accuracy: 0.8095\n",
      "Epoch 156/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3118 - accuracy: 0.8557 - val_loss: 0.3701 - val_accuracy: 0.8333\n",
      "Epoch 157/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3160 - accuracy: 0.8557 - val_loss: 0.3654 - val_accuracy: 0.8333\n",
      "Epoch 158/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2336 - accuracy: 0.9072 - val_loss: 0.3630 - val_accuracy: 0.8333\n",
      "Epoch 159/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3352 - accuracy: 0.8660 - val_loss: 0.3606 - val_accuracy: 0.8333\n",
      "Epoch 160/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2519 - accuracy: 0.8866 - val_loss: 0.3586 - val_accuracy: 0.8333\n",
      "Epoch 161/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3177 - accuracy: 0.8454 - val_loss: 0.3568 - val_accuracy: 0.8333\n",
      "Epoch 162/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3295 - accuracy: 0.8454 - val_loss: 0.3537 - val_accuracy: 0.8333\n",
      "Epoch 163/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3214 - accuracy: 0.8041 - val_loss: 0.3531 - val_accuracy: 0.8333\n",
      "Epoch 164/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3169 - accuracy: 0.8247 - val_loss: 0.3543 - val_accuracy: 0.8333\n",
      "Epoch 165/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2772 - accuracy: 0.8247 - val_loss: 0.3555 - val_accuracy: 0.8333\n",
      "Epoch 166/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2828 - accuracy: 0.8866 - val_loss: 0.3547 - val_accuracy: 0.8333\n",
      "Epoch 167/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2442 - accuracy: 0.8660 - val_loss: 0.3541 - val_accuracy: 0.8333\n",
      "Epoch 168/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3012 - accuracy: 0.8660 - val_loss: 0.3525 - val_accuracy: 0.8333\n",
      "Epoch 169/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3509 - accuracy: 0.8247 - val_loss: 0.3515 - val_accuracy: 0.8333\n",
      "Epoch 170/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.2631 - accuracy: 0.8660 - val_loss: 0.3523 - val_accuracy: 0.8333\n",
      "Epoch 171/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.2910 - accuracy: 0.8351 - val_loss: 0.3550 - val_accuracy: 0.8333\n",
      "Epoch 172/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.2972 - accuracy: 0.8454 - val_loss: 0.3589 - val_accuracy: 0.8333\n",
      "Epoch 173/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3098 - accuracy: 0.8351 - val_loss: 0.3582 - val_accuracy: 0.8333\n",
      "Epoch 174/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.2868 - accuracy: 0.8454 - val_loss: 0.3552 - val_accuracy: 0.8333\n",
      "Epoch 175/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3394 - accuracy: 0.8351 - val_loss: 0.3529 - val_accuracy: 0.8333\n",
      "Epoch 176/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2590 - accuracy: 0.8866 - val_loss: 0.3522 - val_accuracy: 0.8571\n",
      "Epoch 177/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2875 - accuracy: 0.8557 - val_loss: 0.3527 - val_accuracy: 0.8571\n",
      "Epoch 178/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3022 - accuracy: 0.8351 - val_loss: 0.3549 - val_accuracy: 0.8571\n",
      "Epoch 179/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3521 - accuracy: 0.8557 - val_loss: 0.3563 - val_accuracy: 0.8571\n",
      "Epoch 180/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3087 - accuracy: 0.8144 - val_loss: 0.3569 - val_accuracy: 0.8571\n",
      "Epoch 181/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2874 - accuracy: 0.8351 - val_loss: 0.3573 - val_accuracy: 0.8571\n",
      "Epoch 182/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.2524 - accuracy: 0.8763 - val_loss: 0.3581 - val_accuracy: 0.7857\n",
      "Epoch 183/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3200 - accuracy: 0.8454 - val_loss: 0.3597 - val_accuracy: 0.7857\n",
      "Epoch 184/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2505 - accuracy: 0.8557 - val_loss: 0.3597 - val_accuracy: 0.7857\n",
      "Epoch 185/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.2882 - accuracy: 0.8660 - val_loss: 0.3606 - val_accuracy: 0.8571\n",
      "Epoch 186/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2901 - accuracy: 0.8247 - val_loss: 0.3606 - val_accuracy: 0.8571\n",
      "Epoch 187/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2516 - accuracy: 0.8866 - val_loss: 0.3577 - val_accuracy: 0.8571\n",
      "Epoch 188/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.2944 - accuracy: 0.8041 - val_loss: 0.3546 - val_accuracy: 0.8571\n",
      "Epoch 189/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2970 - accuracy: 0.8247 - val_loss: 0.3532 - val_accuracy: 0.8571\n",
      "Epoch 190/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2887 - accuracy: 0.8660 - val_loss: 0.3527 - val_accuracy: 0.8571\n",
      "Epoch 191/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.2743 - accuracy: 0.8351 - val_loss: 0.3524 - val_accuracy: 0.8571\n",
      "Epoch 192/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3022 - accuracy: 0.8351 - val_loss: 0.3529 - val_accuracy: 0.8571\n",
      "Epoch 193/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3015 - accuracy: 0.8247 - val_loss: 0.3519 - val_accuracy: 0.8571\n",
      "Epoch 194/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.2848 - accuracy: 0.8557 - val_loss: 0.3521 - val_accuracy: 0.8571\n",
      "Epoch 195/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.2787 - accuracy: 0.8454 - val_loss: 0.3533 - val_accuracy: 0.8571\n",
      "Epoch 196/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2687 - accuracy: 0.8454 - val_loss: 0.3533 - val_accuracy: 0.8571\n",
      "Epoch 197/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3168 - accuracy: 0.8041 - val_loss: 0.3535 - val_accuracy: 0.8571\n",
      "Epoch 198/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2685 - accuracy: 0.8557 - val_loss: 0.3545 - val_accuracy: 0.8571\n",
      "Epoch 199/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3104 - accuracy: 0.8351 - val_loss: 0.3562 - val_accuracy: 0.8571\n",
      "Epoch 200/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2687 - accuracy: 0.8144 - val_loss: 0.3578 - val_accuracy: 0.8571\n",
      "{0, 1}\n"
     ]
    }
   ],
   "source": [
    "#Creating a Model\n",
    "from keras import models\n",
    "from keras import layers\n",
    "import keras\n",
    "\n",
    "# model 1\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(150, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(32, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(len(y_train), activation='softmax'))\n",
    "\n",
    "# Learning Process of a model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# simple early stopping\n",
    "from keras.callbacks import EarlyStopping\n",
    "es = EarlyStopping(monitor='val_loss', patience=80, verbose=1)\n",
    "print(X_train.shape)\n",
    "#Train with early stopping to avoid overfitting\n",
    "y_train=np.array(y_train, dtype=int)\n",
    "y_val=np.array(y_val, dtype=int)\n",
    "history = model.fit(X_train,y_train,validation_data=(X_val, y_val),epochs=200,batch_size=30, callbacks=[es])\n",
    "print(set(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "7962ca0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot training history\n",
    "from matplotlib import pyplot\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "1f45bb2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "        \n",
    "def printPrediction(X_data, y_data, printDigit, model):\n",
    "    print('\\n# Generate predictions')\n",
    "    for i in range(len(y_data)):\n",
    "        predict_x=model.predict(X_data[i:i+1])[0]\n",
    "        predict_classes = np.argmax(predict_x)\n",
    "        print(predict_classes)\n",
    "        print(max(predict_x))\n",
    "        prediction = predict_classes\n",
    "    \n",
    "        user = y_data[i]\n",
    "        if printDigit == True:\n",
    "           print(\"Number={0:d}, y={1:10d}- prediction={2:10d}- match={3}\".format(i, user, prediction, user==prediction))\n",
    "        else:\n",
    "           print(\"y={0:10d}- prediction={1:10d}- match={2}\".format(user, prediction, user==prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "856c714c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "def report(X_data, y_data):\n",
    "    #Confution Matrix and Classification Report\n",
    "    #predict_y = model.predict_prob(X_data)\n",
    "    predict_y=model.predict(X_data)\n",
    "    Y_pred = np.argmax(predict_y, axis=1)\n",
    "    y_test_num = y_data.astype(np.int64)\n",
    "    conf_mt = confusion_matrix(y_test_num, Y_pred)\n",
    "    print(conf_mt[len(set(y_test_num))-1])\n",
    "    key=0\n",
    "    for val in conf_mt[len(set(y_test_num))-1]:\n",
    "        if val!=0:\n",
    "            print(key)\n",
    "        key=key+1\n",
    "    conf_mt=conf_mt / conf_mt.astype(np.float).sum(axis=1)\n",
    "    #print(conf_mt)\n",
    "    plt.matshow(conf_mt)\n",
    "    plt.show()\n",
    "    print('\\nClassification Report')\n",
    "    print(classification_report(y_test_num, Y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "af65a29f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# TEST DATA #\n",
      "\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4178 - accuracy: 0.8000\n",
      "accuracy: 80.00%\n",
      "\n",
      "# Generate predictions\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "0\n",
      "0.9999999\n",
      "y=         0- prediction=         0- match=True\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1\n",
      "0.6155033\n",
      "y=         0- prediction=         1- match=False\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "0\n",
      "0.99999964\n",
      "y=         0- prediction=         0- match=True\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "0\n",
      "0.99997056\n",
      "y=         0- prediction=         0- match=True\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1\n",
      "0.6769116\n",
      "y=         0- prediction=         1- match=False\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "0\n",
      "0.9995677\n",
      "y=         0- prediction=         0- match=True\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "0\n",
      "0.9987392\n",
      "y=         0- prediction=         0- match=True\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1\n",
      "0.6099193\n",
      "y=         0- prediction=         1- match=False\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "0\n",
      "0.99994767\n",
      "y=         0- prediction=         0- match=True\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "0\n",
      "1.0\n",
      "y=         0- prediction=         0- match=True\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "0\n",
      "0.99989223\n",
      "y=         0- prediction=         0- match=True\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "0\n",
      "0.56632185\n",
      "y=         0- prediction=         0- match=True\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "0\n",
      "0.9999788\n",
      "y=         0- prediction=         0- match=True\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "0\n",
      "0.99999213\n",
      "y=         0- prediction=         0- match=True\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "0\n",
      "0.99884987\n",
      "y=         0- prediction=         0- match=True\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "0\n",
      "0.999979\n",
      "y=         0- prediction=         0- match=True\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "0\n",
      "0.9999113\n",
      "y=         0- prediction=         0- match=True\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "0\n",
      "0.9999789\n",
      "y=         0- prediction=         0- match=True\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "0\n",
      "0.9949645\n",
      "y=         0- prediction=         0- match=True\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "0\n",
      "0.9996475\n",
      "y=         0- prediction=         0- match=True\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1\n",
      "0.9799029\n",
      "y=         1- prediction=         1- match=True\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1\n",
      "0.9798282\n",
      "y=         1- prediction=         1- match=True\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "0\n",
      "0.7507733\n",
      "y=         1- prediction=         0- match=False\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "0\n",
      "0.6387042\n",
      "y=         1- prediction=         0- match=False\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1\n",
      "0.6101554\n",
      "y=         1- prediction=         1- match=True\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1\n",
      "0.9797177\n",
      "y=         1- prediction=         1- match=True\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1\n",
      "0.9796126\n",
      "y=         1- prediction=         1- match=True\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1\n",
      "0.6138283\n",
      "y=         1- prediction=         1- match=True\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "0\n",
      "0.7483499\n",
      "y=         1- prediction=         0- match=False\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1\n",
      "0.6140913\n",
      "y=         1- prediction=         1- match=True\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1\n",
      "0.97963274\n",
      "y=         1- prediction=         1- match=True\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "0\n",
      "0.982275\n",
      "y=         1- prediction=         0- match=False\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1\n",
      "0.52196074\n",
      "y=         1- prediction=         1- match=True\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1\n",
      "0.61302453\n",
      "y=         1- prediction=         1- match=True\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1\n",
      "0.61405945\n",
      "y=         1- prediction=         1- match=True\n"
     ]
    }
   ],
   "source": [
    "print('\\n# TEST DATA #\\n')\n",
    "y_test=np.array(y_test, dtype=int)\n",
    "score = model.evaluate(X_test, y_test)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], score[1]*100))\n",
    "# Prediction\n",
    "printPrediction(X_test, y_test, False, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "9c7d7c7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for Test Data\n",
      "\n",
      "(35,)\n",
      "(35, 14)\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "[ 4 11]\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 480x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.85      0.83        20\n",
      "           1       0.79      0.73      0.76        15\n",
      "\n",
      "    accuracy                           0.80        35\n",
      "   macro avg       0.80      0.79      0.79        35\n",
      "weighted avg       0.80      0.80      0.80        35\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification Report for Test Data\\n\")\n",
    "print(y_test.shape)\n",
    "print(X_test.shape)\n",
    "report(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "a3129eee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../behavior_scaler.save']"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "model.save('../behavior-recognition.h5')\n",
    "joblib.dump(scaler, '../behavior_scaler.save') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a837d2c",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e68a906",
   "metadata": {},
   "source": [
    "os.chdir (\"/home/silvia/Escritorio/tfm/Server_auth/behavior/test\")\n",
    "extension = 'csv'\n",
    "files=[i for i in glob.glob('*.{}'.format(extension))]\n",
    "print(files)\n",
    "test = pd.concat([pd.read_csv(f) for f in files])\n",
    "test=test.sample(frac=1).reset_index(drop=True)\n",
    "test=test.drop(columns='time_secs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "59f09101",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj=[\n",
    "    \"time_secs,scrolling,mouse_clicks,e_legend_clicks,e_map_clicks,map_clicks,general_clicks,close_top_clicks,close_bottom_clicks,go_clicks,map_zoom,mouse_mov,key_presses,priority,order,user\",\n",
    "    [\n",
    "        5,\n",
    "        0,\n",
    "        0.6,\n",
    "        0,\n",
    "        0.6666666666666666,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0.3333333333333333,\n",
    "        0,\n",
    "        62,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        1\n",
    "    ],\n",
    "    [\n",
    "        10,\n",
    "        0,\n",
    "        0.7,\n",
    "        0,\n",
    "        0.5714285714285714,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0.2857142857142857,\n",
    "        0.14285714285714285,\n",
    "        0,\n",
    "        66.7,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        1\n",
    "    ],\n",
    "    [\n",
    "        15,\n",
    "        0,\n",
    "        0.6666666666666666,\n",
    "        0,\n",
    "        0.5,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0.4,\n",
    "        0.1,\n",
    "        0,\n",
    "        60.8,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        1\n",
    "    ],\n",
    "    [\n",
    "        20,\n",
    "        0,\n",
    "        0.5,\n",
    "        0,\n",
    "        0.5,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0.4,\n",
    "        0.1,\n",
    "        0,\n",
    "        45.6,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        1\n",
    "    ],\n",
    "    [\n",
    "        25,\n",
    "        0,\n",
    "        0.4,\n",
    "        0,\n",
    "        0.5,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0.4,\n",
    "        0.1,\n",
    "        0,\n",
    "        36.48,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        1\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "21b3b9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test=pd.DataFrame([x for i, x in enumerate(array) if i!=0], columns=array[0].split(','))\n",
    "test=test.drop(columns='time_secs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "2e3ea3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict():\n",
    "    \n",
    "    X_test = np.array(test.iloc[:, :-1], dtype = float)\n",
    "    y_test = test.iloc[:, -1]\n",
    "    \n",
    "    X_test = scaler.transform( X_test )\n",
    "    #y_test=np.array(y_test, dtype=int)\n",
    "    \n",
    "    score = new_model.evaluate(X_test, y_test)\n",
    "    # Prediction\n",
    "    print(X_test, y_test, False, new_model)\n",
    "    print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628e8ed3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "47e56d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = keras.models.load_model('../behavior-recognition.h5')\n",
    "scaler = joblib.load('../behavior_scaler.save') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "5f3dde54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0205 - accuracy: 1.0000\n",
      "\n",
      "# Generate predictions\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1\n",
      "0.97972065\n",
      "y=         1- prediction=         1- match=True\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1\n",
      "0.9797816\n",
      "y=         1- prediction=         1- match=True\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1\n",
      "0.9797794\n",
      "y=         1- prediction=         1- match=True\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1\n",
      "0.97972316\n",
      "y=         1- prediction=         1- match=True\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1\n",
      "0.9796886\n",
      "y=         1- prediction=         1- match=True\n",
      "0    1\n",
      "1    1\n",
      "2    1\n",
      "3    1\n",
      "4    1\n",
      "Name: user, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad93b71",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
